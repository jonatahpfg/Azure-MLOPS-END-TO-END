"""
===================================================================
SCRIPT DE TESTE DO ENDPOINT
===================================================================
Descri√ß√£o: Testa o endpoint de infer√™ncia deployado
- Envia requisi√ß√µes de teste
- Valida respostas
- Mede lat√™ncia

Uso:
    python test_endpoint.py --endpoint_url <url> --api_key <key>

===================================================================
"""

import os
import sys
import json
import logging
import time
import requests
import pandas as pd
import numpy as np
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_args():
    import argparse
    parser = argparse.ArgumentParser(description="Testa endpoint de infer√™ncia")
    parser.add_argument(
        "--num_samples",
        type=int,
        default=5,
        help="N√∫mero de amostras de teste (padr√£o: 5)"
    )
    parser.add_argument(
        "--subscription_id",
        type=str,
        required=False,
        help="Azure Subscription ID (opcional, pode usar login local)"
    )
    parser.add_argument(
        "--resource_group",
        type=str,
        required=False,
        help="Azure Resource Group (opcional)"
    )
    parser.add_argument(
        "--workspace_name",
        type=str,
        required=False,
        help="Azure ML Workspace Name (opcional)"
    )
    return parser.parse_args()


def generate_sample_data(num_samples: int) -> dict:
    """Gera dados de teste reais para validar o preprocessor na nuvem."""
    logger.info(f"Gerando {num_samples} amostras de teste reais...")
    
    # Criamos uma lista de dicion√°rios com as 19 colunas obrigat√≥rias
    samples = []
    for _ in range(num_samples):
        samples.append({
            "gender": "Female", "SeniorCitizen": 0, "Partner": "Yes", 
            "Dependents": "No", "tenure": 1, "PhoneService": "No", 
            "MultipleLines": "No phone service", "InternetService": "DSL", 
            "OnlineSecurity": "No", "OnlineBackup": "Yes", 
            "DeviceProtection": "No", "TechSupport": "No", 
            "StreamingTV": "No", "StreamingMovies": "No", 
            "Contract": "Month-to-month", "PaperlessBilling": "Yes", 
            "PaymentMethod": "Electronic check", "MonthlyCharges": 29.85, 
            "TotalCharges": "29.85"
        })
    
    # O Azure ML espera os dados dentro de uma chave 'data'
    return {"data": samples}

def test_endpoint(endpoint_url: str, api_key: str, data: dict) -> dict:
    """
    Testa o endpoint com dados fornecidos.
    """
    try:
        logger.info(f"Enviando requisi√ß√£o para: {endpoint_url}")
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        start_time = time.time()
        response = requests.post(
            endpoint_url,
            json=data,
            headers=headers,
            timeout=30
        )
        latency = (time.time() - start_time) * 1000  # em ms
        response.raise_for_status()
        result = response.json()
        logger.info(f"‚úÖ Resposta recebida (lat√™ncia: {latency:.2f}ms)")
        return {
            "success": True,
            "latency_ms": latency,
            "status_code": response.status_code,
            "result": result
        }
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå Erro na requisi√ß√£o: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def analyze_results(results: list):
    """
    Analisa resultados dos testes.
    
    Args:
        results: Lista de resultados
    """
    logger.info("\n" + "="*70)
    logger.info("AN√ÅLISE DOS RESULTADOS")
    logger.info("="*70)
    
    successes = [r for r in results if r.get("success")]
    failures = [r for r in results if not r.get("success")]
    
    logger.info(f"‚úÖ Sucessos: {len(successes)}/{len(results)}")
    logger.info(f"‚ùå Falhas: {len(failures)}/{len(results)}")
    
    if successes:
        latencies = [r["latency_ms"] for r in successes]
        logger.info(f"\nüìä Lat√™ncia:")
        logger.info(f"   - M√≠nima: {min(latencies):.2f}ms")
        logger.info(f"   - M√°xima: {max(latencies):.2f}ms")
        logger.info(f"   - M√©dia: {np.mean(latencies):.2f}ms")
        logger.info(f"   - P95: {np.percentile(latencies, 95):.2f}ms")
    
    logger.info("="*70)


def validate_predictions(result: dict):
    """
    Valida formato das predi√ß√µes.
    
    Args:
        result: Resultado do endpoint
    """
    try:
        if isinstance(result, list):
            for pred in result:
                assert "churn_prediction" in pred, "Falta 'churn_prediction'"
                assert "churn_probability" in pred, "Falta 'churn_probability'"
                
                # Valida valores
                assert pred["churn_prediction"] in [0, 1], "Predi√ß√£o deve ser 0 ou 1"
                assert 0 <= pred["churn_probability"] <= 1, "Probabilidade deve estar entre 0 e 1"
            
            logger.info("‚úÖ Formato das predi√ß√µes validado")
        else:
            logger.warning(" Formato de resposta inesperado")
            
    except AssertionError as e:
        logger.error(f"‚ùå Valida√ß√£o falhou: {str(e)}")


def main():
    """Fun√ß√£o principal."""
    args = parse_args()
    logger.info("="*70)
    logger.info("TESTE DO ENDPOINT DE INFER√äNCIA")
    logger.info("="*70)

    # Conecta ao Azure ML
    subscription_id = args.subscription_id or os.environ.get("AZURE_SUBSCRIPTION_ID")
    resource_group = args.resource_group or os.environ.get("AZURE_RESOURCE_GROUP")
    workspace_name = args.workspace_name or os.environ.get("AZURE_WORKSPACE_NAME")
    ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)

    # Recupera nome do endpoint do ambiente
    endpoint_name = os.environ.get("DEPLOYED_ENDPOINT_NAME")
    if not endpoint_name:
        logger.error("Vari√°vel de ambiente DEPLOYED_ENDPOINT_NAME n√£o definida!")
        return
    endpoint = ml_client.online_endpoints.get(name=endpoint_name)
    scoring_uri = endpoint.scoring_uri
    keys = ml_client.online_endpoints.get_keys(name=endpoint_name)
    api_key = keys.primary_key

    # Gera dados de teste
    test_data = generate_sample_data(args.num_samples)
    num_tests = 10
    logger.info(f"\nExecutando {num_tests} testes...")
    results = []
    for i in range(num_tests):
        logger.info(f"\nüß™ Teste {i+1}/{num_tests}")
        result = test_endpoint(scoring_uri, api_key, test_data)
        results.append(result)
        if i == 0 and result.get("success"):
            validate_predictions(result.get("result"))
        time.sleep(0.5)
    analyze_results(results)
    
    num_success = sum(1 for r in results if r.get("success"))
    if num_success < num_tests:
        logger.error(f"‚ùå Apenas {num_success}/{num_tests} testes foram bem-sucedidos. Interrompendo pipeline!")
        sys.exit(1)
    else:
        logger.info(f"\n‚úÖ Todos os {num_tests} testes passaram! Endpoint est√° est√°vel e pronto para produ√ß√£o.")


if __name__ == "__main__":
    main()
